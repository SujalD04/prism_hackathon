{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# --- Configuration ---\n",
        "N_DEVICES = 30\n",
        "N_FAILING_DEVICES = 9 # Making it a multiple of 3 for easy division\n",
        "TIME_START = datetime(2023, 1, 1)\n",
        "TIME_END = datetime(2023, 12, 31)\n",
        "SAMPLING_INTERVAL_HOURS = 2\n",
        "\n",
        "# --- MODIFIED Function to generate data for a single device ---\n",
        "def generate_watch_data(device_id, failure_type=\"healthy\"):\n",
        "    \"\"\"\n",
        "    Generates a time-series dataset for a single smartwatch with specific failure types.\n",
        "    \"\"\"\n",
        "    timestamps = pd.to_datetime(np.arange(TIME_START, TIME_END, timedelta(hours=SAMPLING_INTERVAL_HOURS)))\n",
        "    n_samples = len(timestamps)\n",
        "    df = pd.DataFrame({'timestamp': timestamps, 'watch_id': device_id})\n",
        "\n",
        "    # --- Generate features for a healthy smartwatch ---\n",
        "    df['battery_level'] = 100 - (np.sin(np.arange(n_samples) / (24 / SAMPLING_INTERVAL_HOURS) * np.pi) + 1) * 45 + np.random.normal(0, 2, n_samples)\n",
        "    df['heart_rate_bpm'] = np.random.normal(70, 15, n_samples) + np.sin(np.arange(n_samples) / 50) * 10\n",
        "    df['steps_per_hour'] = np.random.poisson(300, n_samples) * (np.sin(np.arange(n_samples) / (24 / SAMPLING_INTERVAL_HOURS) * np.pi) > 0.5)\n",
        "    df['gps_active'] = np.random.choice([0, 1], size=n_samples, p=[0.95, 0.05])\n",
        "    df['screen_on_time_minutes'] = np.random.exponential(5, n_samples)\n",
        "    df['ambient_temp_c'] = np.random.uniform(15, 35, n_samples) + np.sin(np.arange(n_samples) / (365 * 24 / SAMPLING_INTERVAL_HOURS) * 2 * np.pi) * 5\n",
        "    df['water_pressure_atm'] = np.random.normal(1.0, 0.01, n_samples)\n",
        "    df['fall_detection_events'] = np.random.poisson(0.001, n_samples)\n",
        "\n",
        "    # --- Introduce anomalies for failing devices ---\n",
        "    if failure_type != \"healthy\":\n",
        "        failure_point = int(n_samples * np.random.uniform(0.8, 0.95))\n",
        "        degradation_period = int(n_samples * 0.20)\n",
        "        degradation_start_index = failure_point - degradation_period\n",
        "        num_degradation_samples = n_samples - degradation_start_index\n",
        "\n",
        "        if failure_type == \"battery_failure\":\n",
        "            print(f\"Injecting '{failure_type}' for {device_id}\")\n",
        "            df.loc[degradation_start_index:, 'battery_level'] *= np.linspace(1, 0.4, num_degradation_samples) # More aggressive drain\n",
        "            df.loc[degradation_start_index:, 'ambient_temp_c'] += np.linspace(0, 8, num_degradation_samples) # Battery gets warm\n",
        "\n",
        "        elif failure_type == \"heart_rate_sensor_failure\":\n",
        "            print(f\"Injecting '{failure_type}' for {device_id}\")\n",
        "            df.loc[degradation_start_index:, 'heart_rate_bpm'] += np.random.normal(0, 20, num_degradation_samples) + np.linspace(0, 35, num_degradation_samples) # More erratic\n",
        "\n",
        "        elif failure_type == \"water_seal_failure\":\n",
        "            print(f\"Injecting '{failure_type}' for {device_id}\")\n",
        "            df.loc[degradation_start_index:, 'water_pressure_atm'] += np.random.normal(0, 0.2, num_degradation_samples) + np.linspace(0, 0.8, num_degradation_samples) # Stronger, more erratic signal\n",
        "            df.loc[degradation_start_index:, 'battery_level'] *= 0.95 # Slight battery drain from shorting\n",
        "\n",
        "        # Set target variable\n",
        "        df['failed_in_next_7d'] = 0\n",
        "        failure_window_start = failure_point - int(7 * 24 / SAMPLING_INTERVAL_HOURS)\n",
        "        df.loc[failure_window_start:failure_point, 'failed_in_next_7d'] = 1\n",
        "    else:\n",
        "        df['failed_in_next_7d'] = 0\n",
        "\n",
        "    # Clip values\n",
        "    df['battery_level'] = df['battery_level'].clip(0, 100)\n",
        "    df['heart_rate_bpm'] = df['heart_rate_bpm'].clip(30, 220)\n",
        "    df['steps_per_hour'] = df['steps_per_hour'].clip(0)\n",
        "    return df\n",
        "\n",
        "# --- Generate data for all watches and combine ---\n",
        "all_watches_df = []\n",
        "failing_watch_ids = [f\"watch_{i:03d}\" for i in range(N_FAILING_DEVICES)]\n",
        "random.shuffle(failing_watch_ids)\n",
        "\n",
        "# --- MODIFIED Main Loop to assign different failures ---\n",
        "failure_types = [\"battery_failure\", \"heart_rate_sensor_failure\", \"water_seal_failure\"]\n",
        "watch_id_to_failure = {}\n",
        "for i, watch_id in enumerate(failing_watch_ids):\n",
        "    watch_id_to_failure[watch_id] = failure_types[i % len(failure_types)]\n",
        "\n",
        "\n",
        "for i in tqdm(range(N_DEVICES), desc=\"Generating Device Data\"):\n",
        "    device_id = f\"watch_{i:03d}\"\n",
        "    failure_type = watch_id_to_failure.get(device_id, \"healthy\")\n",
        "    watch_df = generate_watch_data(device_id, failure_type)\n",
        "    all_watches_df.append(watch_df)\n",
        "\n",
        "final_df = pd.concat(all_watches_df, ignore_index=True)\n",
        "\n",
        "# --- Save to new CSV ---\n",
        "output_filename = 'smartwatch_telemetry_v2.csv'\n",
        "final_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nâœ… Enhanced smartwatch telemetry dataset generated successfully!\")\n",
        "print(f\"ğŸ“„ Saved to '{output_filename}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM1QDYD_9yE8",
        "outputId": "8e95a365-2b77-40f6-ed3a-e5d948da523f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Device Data:  17%|â–ˆâ–‹        | 5/30 [00:00<00:00, 49.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injecting 'battery_failure' for watch_000\n",
            "Injecting 'heart_rate_sensor_failure' for watch_001\n",
            "Injecting 'water_seal_failure' for watch_002\n",
            "Injecting 'heart_rate_sensor_failure' for watch_003\n",
            "Injecting 'heart_rate_sensor_failure' for watch_004\n",
            "Injecting 'battery_failure' for watch_005\n",
            "Injecting 'water_seal_failure' for watch_006\n",
            "Injecting 'water_seal_failure' for watch_007\n",
            "Injecting 'battery_failure' for watch_008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Device Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 54.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Enhanced smartwatch telemetry dataset generated successfully!\n",
            "ğŸ“„ Saved to 'smartwatch_telemetry_v2.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_CSV = \"/content/smartwatch_telemetry_v2.csv\"\n",
        "OUTPUT_PATH = \".\"\n",
        "\n",
        "# Define the sequence length based on the data's 2-hour interval\n",
        "SAMPLING_INTERVAL_HOURS = 2\n",
        "TIMESTEPS_PER_DAY = 24 // SAMPLING_INTERVAL_HOURS\n",
        "SEQUENCE_DAYS = 14  # Look at 14 days of history for each prediction\n",
        "SEQUENCE_TIMESTEPS = SEQUENCE_DAYS * TIMESTEPS_PER_DAY\n",
        "\n",
        "def prepare_smartwatch_data():\n",
        "    \"\"\"\n",
        "    Loads raw smartwatch data, scales it, creates sequences, and saves the final arrays.\n",
        "    \"\"\"\n",
        "    print(\"--- Step 1: Loading and Preprocessing Data ---\")\n",
        "\n",
        "    try:\n",
        "        # Define efficient data types for smartwatch features\n",
        "        dtype_map = {\n",
        "            'battery_level': 'float32', 'heart_rate_bpm': 'float32',\n",
        "            'steps_per_hour': 'int16', 'gps_active': 'int8',\n",
        "            'screen_on_time_minutes': 'float32', 'ambient_temp_c': 'float32',\n",
        "            'water_pressure_atm': 'float32', 'fall_detection_events': 'int8',\n",
        "            'failed_in_next_7d': 'int8'\n",
        "        }\n",
        "        df = pd.read_csv(INPUT_CSV, dtype=dtype_map, parse_dates=['timestamp'])\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{INPUT_CSV}' was not found.\")\n",
        "        return\n",
        "\n",
        "    df.sort_values(by=['watch_id', 'timestamp'], inplace=True)\n",
        "    print(f\"Loaded {len(df)} data points from {df['watch_id'].nunique()} devices.\")\n",
        "\n",
        "    # --- Step 2: Scaling Features ---\n",
        "\n",
        "    # Define the features the LSTM will use\n",
        "    feature_columns = [\n",
        "        'battery_level', 'heart_rate_bpm', 'steps_per_hour', 'gps_active',\n",
        "        'screen_on_time_minutes', 'ambient_temp_c', 'water_pressure_atm',\n",
        "        'fall_detection_events'\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n--- Step 2: Scaling {len(feature_columns)} Features ---\")\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
        "\n",
        "    scaler_filename = os.path.join(OUTPUT_PATH, \"smartwatch_scaler.joblib\")\n",
        "    joblib.dump(scaler, scaler_filename)\n",
        "    print(f\"Scaler saved to '{scaler_filename}'.\")\n",
        "\n",
        "    # --- Step 3: Creating Sequences ---\n",
        "\n",
        "    print(f\"\\n--- Step 3: Creating Sequences with {SEQUENCE_TIMESTEPS} Timesteps ({SEQUENCE_DAYS} days) ---\")\n",
        "\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Group data by each watch to create sequences separately\n",
        "    grouped_data = df.groupby('watch_id')\n",
        "\n",
        "    for watch_id, watch_data in tqdm(grouped_data, desc=\"Processing Watches\"):\n",
        "        feature_data = watch_data[feature_columns].values\n",
        "        label_data = watch_data['failed_in_next_7d'].values\n",
        "\n",
        "        for i in range(len(feature_data) - SEQUENCE_TIMESTEPS):\n",
        "            seq = feature_data[i:i + SEQUENCE_TIMESTEPS]\n",
        "            label = label_data[i + SEQUENCE_TIMESTEPS - 1]\n",
        "\n",
        "            sequences.append(seq)\n",
        "            labels.append(label)\n",
        "\n",
        "    X = np.array(sequences)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    print(\"\\n--- Step 4: Finalizing and Saving Data ---\")\n",
        "    print(f\"Final shape of sequences (X): {X.shape}\")\n",
        "    print(f\"Final shape of labels (y): {y.shape}\")\n",
        "\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"smartwatch_sequences.npy\"), X)\n",
        "    np.save(os.path.join(OUTPUT_PATH, \"smartwatch_labels.npy\"), y)\n",
        "\n",
        "    print(f\"\\nData preparation complete. Model-ready files saved.\")\n",
        "    print(\"You are now ready for the final step: training the LSTM model.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prepare_smartwatch_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeLck-hBd0QL",
        "outputId": "74724295-8e8f-4cc0-f2b7-35a66506c0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Loading and Preprocessing Data ---\n",
            "Loaded 131040 data points from 30 devices.\n",
            "\n",
            "--- Step 2: Scaling 8 Features ---\n",
            "Scaler saved to './smartwatch_scaler.joblib'.\n",
            "\n",
            "--- Step 3: Creating Sequences with 168 Timesteps (14 days) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Watches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 215.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Finalizing and Saving Data ---\n",
            "Final shape of sequences (X): (126000, 168, 8)\n",
            "Final shape of labels (y): (126000,)\n",
            "\n",
            "Data preparation complete. Model-ready files saved.\n",
            "You are now ready for the final step: training the LSTM model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Step 0: Setup and GPU Check ---\n",
        "# (Same as before)\n",
        "print(\"--- Step 0: Setup and GPU Check ---\")\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if not '/device:GPU:0' in device_name:\n",
        "  print('\\nWARNING: GPU device not found.')\n",
        "else:\n",
        "  print('\\nSUCCESS: Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n",
        "# --- Step 1: Load and Split Data ---\n",
        "# (Same as before)\n",
        "print(\"\\n--- Step 1: Loading and Splitting Data ---\")\n",
        "X = np.load('smartwatch_sequences.npy')\n",
        "y = np.load('smartwatch_labels.npy')\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- Step 2: Handle Class Imbalance ---\n",
        "# (Same as before)\n",
        "print(\"\\n--- Step 2: Calculating Class Weights ---\")\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "print(f\"Calculated class weights: {class_weight_dict}\")\n",
        "\n",
        "\n",
        "# --- Step 3: Build the LSTM Model Architecture ---\n",
        "# (Same as before)\n",
        "print(\"\\n--- Step 3: Building the LSTM Model ---\")\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=input_shape, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- Step 4: Compile and Train the Model (MODIFIED) ---\n",
        "print(\"\\n--- Step 4: Compiling and Training the Model ---\")\n",
        "\n",
        "# FIX 1: Use a lower learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# FIX 2: Define callbacks for smarter training\n",
        "# Stop training if the validation loss doesn't improve for 3 epochs\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True # Automatically restore the best model\n",
        ")\n",
        "# Reduce the learning rate if validation loss plateaus\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2, # Reduce by a factor of 5\n",
        "    patience=2\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
        ")\n",
        "\n",
        "# Train the model with the new callbacks\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=20, # We can still set a max, but EarlyStopping will likely finish first\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stopping, reduce_lr] # Add the callbacks here\n",
        ")\n",
        "\n",
        "\n",
        "# --- Step 5: Evaluate the Model ---\n",
        "# (Same as before)\n",
        "print(\"\\n--- Step 5: Evaluating Model Performance ---\")\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "print(\"\\nClassification Report (from best model):\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Healthy', 'Failure Imminent']))\n",
        "\n",
        "# --- Step 6: Save the Trained Model ---\n",
        "# (Same as before)\n",
        "MODEL_FILENAME = 'smartwatch_model_v2.h5'\n",
        "model.save(MODEL_FILENAME)\n",
        "print(f\"\\nModel training and evaluation complete. Best model saved to '{MODEL_FILENAME}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "90dRo6VnlSO9",
        "outputId": "471d51eb-af90-4988-c58a-f59ee011d039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 0: Setup and GPU Check ---\n",
            "\n",
            "WARNING: GPU device not found.\n",
            "\n",
            "--- Step 1: Loading and Splitting Data ---\n",
            "\n",
            "--- Step 2: Calculating Class Weights ---\n",
            "Calculated class weights: {0: np.float64(0.5030542579949695), 1: np.float64(82.3529411764706)}\n",
            "\n",
            "--- Step 3: Building the LSTM Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m18,688\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,801\u001b[0m (81.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,801</span> (81.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,801\u001b[0m (81.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,801</span> (81.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Compiling and Training the Model ---\n",
            "Epoch 1/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 210ms/step - accuracy: 0.8424 - loss: 0.5834 - precision: 0.0208 - recall: 0.4637 - val_accuracy: 0.9305 - val_loss: 0.2315 - val_precision: 0.0790 - val_recall: 0.9804 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 210ms/step - accuracy: 0.8902 - loss: 0.2240 - precision: 0.0570 - recall: 0.9857 - val_accuracy: 0.7707 - val_loss: 0.4698 - val_precision: 0.0258 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - accuracy: 0.8896 - loss: 0.2060 - precision: 0.0516 - recall: 0.9928 - val_accuracy: 0.9038 - val_loss: 0.2671 - val_precision: 0.0593 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 211ms/step - accuracy: 0.9349 - loss: 0.1309 - precision: 0.0867 - recall: 0.9985 - val_accuracy: 0.9348 - val_loss: 0.1816 - val_precision: 0.0851 - val_recall: 1.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 214ms/step - accuracy: 0.9375 - loss: 0.1278 - precision: 0.0885 - recall: 0.9987 - val_accuracy: 0.9355 - val_loss: 0.1908 - val_precision: 0.0861 - val_recall: 1.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - accuracy: 0.9293 - loss: 0.1392 - precision: 0.0776 - recall: 0.9928 - val_accuracy: 0.9362 - val_loss: 0.1863 - val_precision: 0.0869 - val_recall: 1.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - accuracy: 0.9360 - loss: 0.1288 - precision: 0.0879 - recall: 0.9987 - val_accuracy: 0.9369 - val_loss: 0.1858 - val_precision: 0.0878 - val_recall: 1.0000 - learning_rate: 4.0000e-06\n",
            "\n",
            "--- Step 5: Evaluating Model Performance ---\n",
            "\u001b[1m788/788\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (from best model):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         Healthy       1.00      0.93      0.97     25047\n",
            "Failure Imminent       0.09      1.00      0.16       153\n",
            "\n",
            "        accuracy                           0.93     25200\n",
            "       macro avg       0.54      0.97      0.56     25200\n",
            "    weighted avg       0.99      0.93      0.96     25200\n",
            "\n",
            "\n",
            "Model training and evaluation complete. Best model saved to 'smartwatch_model_v2.h5'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FILENAME = 'smartwatch_model_v2.h5'\n",
        "model.save(MODEL_FILENAME)\n",
        "print(f\"\\nModel training and evaluation complete. Best model saved to '{MODEL_FILENAME}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCycsPAvdEmL",
        "outputId": "8ccd6b37-98f8-4cdd-89b5-35d43d8e62b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model training and evaluation complete. Best model saved to 'smartwatch_model_v2.h5'.\n"
          ]
        }
      ]
    }
  ]
}
# -*- coding: utf-8 -*-
"""smartphone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AjWzMtAgrTFUMwx93ZuW2sefaTkxneeD
"""

# ==============================================================================
# Smartphone Predictive Maintenance Pipeline
#   – Simulation + Dataset + LSTM Training/Evaluation
# ==============================================================================

import json, uuid, random
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from tqdm import tqdm
import joblib

# ------------------ 1️⃣  Simulation Engine ------------------
class DeviceSimulator:
    def __init__(self, device_type, model_name, failure_type):
        self.device_id = f"{device_type.replace('_','-')}-{uuid.uuid4()}"
        self.device_type, self.model_name, self.failure_type = device_type, model_name, failure_type
        self.current_time = datetime.utcnow() - timedelta(days=random.randint(30, 90))
        self.time_step = timedelta(hours=random.randint(1, 4))
        self.state = self.get_healthy_state()

    def get_healthy_state(self): raise NotImplementedError
    def simulate_failure_step(self): raise NotImplementedError

    def generate_record(self, is_failing=False):
        record = {
            "recordId": str(uuid.uuid4()),
            "deviceId": self.device_id,
            "deviceType": self.device_type,
            "timestamp": self.current_time.isoformat() + "Z",
            "modelName": self.model_name,
            "metrics": self.state.copy(),
            "label": {
                "failure_imminent": is_failing,
                "failure_type": self.failure_type if is_failing else "none"
            }
        }
        self.current_time += self.time_step
        return record

    def run_simulation(self, healthy_records=50, failing_records=10):
        dataset = []
        for _ in range(healthy_records):
            self.state = self.get_healthy_state()
            dataset.append(self.generate_record(False))
        for _ in range(failing_records):
            self.simulate_failure_step()
            dataset.append(self.generate_record(True))
        return dataset


# ---- Smartphone Only ----
class SmartphoneSimulator(DeviceSimulator):
    def __init__(self):
        super().__init__("smartphone", "Samsung Galaxy S25 Ultra",
                         "battery_degradation_failure")

    def get_healthy_state(self):
        return {
            "charge_cycles": random.randint(50, 150),
            "max_capacity_mah": random.randint(4850, 4950),
            "power_draw_w": round(random.uniform(1.5, 2.5), 2),
            "unexpected_shutdown_flag": 0
        }

    def simulate_failure_step(self):
        self.state["charge_cycles"] += random.randint(20, 30)
        self.state["max_capacity_mah"] -= random.randint(70, 120)
        self.state["power_draw_w"] += round(random.uniform(0.1, 0.3), 2)
        if self.state["max_capacity_mah"] < 3500 and random.random() < 0.3:
            self.state["unexpected_shutdown_flag"] = 1

print("✅ Smartphone simulator ready.")

# ------------------ 2️⃣  Generate Dataset ------------------
DEVICE_COUNT = 400   # number of smartphones to simulate
master_dataset = []

for _ in tqdm(range(DEVICE_COUNT), desc="Simulating smartphones"):
    sim = SmartphoneSimulator()
    narrative = sim.run_simulation(
        healthy_records=random.randint(30, 50),
        failing_records=random.randint(10, 15)
    )
    master_dataset.extend(narrative)

random.shuffle(master_dataset)
with open('smartphone_device_narratives.json', 'w') as f:
    json.dump(master_dataset, f)
print(f"✅ Dataset generated with {len(master_dataset):,} records.")

# ------------------ 3️⃣  Data Prep for LSTM ------------------
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf

df = pd.read_json('smartphone_device_narratives.json')
df_metrics = pd.json_normalize(df['metrics'])
df_labels  = pd.json_normalize(df['label'])
df = pd.concat([df.drop(['metrics','label','recordId','modelName'], axis=1),
                df_metrics, df_labels], axis=1)
df.fillna(0, inplace=True)

df['timestamp'] = pd.to_datetime(df['timestamp'])
df.sort_values(by=['deviceId','timestamp'], inplace=True)
df['failure_imminent'] = df['failure_imminent'].astype(int)

feature_columns = [c for c in df.columns if c not in
                   ['deviceId','deviceType','timestamp','failure_type','failure_imminent']]
print("Feature columns:", feature_columns)

scaler = StandardScaler()
df[feature_columns] = scaler.fit_transform(df[feature_columns])
joblib.dump(scaler, 'smartphone_lstm_scaler.joblib')

train_ids, test_ids = train_test_split(df['deviceId'].unique(), test_size=0.25, random_state=42)
train_df = df[df['deviceId'].isin(train_ids)]
test_df  = df[df['deviceId'].isin(test_ids)]

SEQUENCE_LENGTH = 10
def create_sequences(data_df, features, target_col):
    X, y = [], []
    for _, g in data_df.groupby('deviceId'):
        feat = g[features].values
        labels = g[target_col].values
        for i in range(len(g) - SEQUENCE_LENGTH):
            X.append(feat[i:i+SEQUENCE_LENGTH])
            y.append(labels[i+SEQUENCE_LENGTH])
    return np.array(X), np.array(y)

X_train, y_train = create_sequences(train_df, feature_columns, 'failure_imminent')
X_test,  y_test  = create_sequences(test_df,  feature_columns, 'failure_imminent')
print("Train shape:", X_train.shape, "Test shape:", X_test.shape)

# ------------------ 4️⃣  LSTM Model ------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping

tf.keras.backend.clear_session()
model = Sequential([
    Input(shape=(X_train.shape[1], X_train.shape[2])),
    LSTM(64, return_sequences=False),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=64,
    validation_split=0.2,
    callbacks=[early_stopping],
    verbose=1
)

model.save('smartphone_lstm_model.keras')
joblib.dump(feature_columns, 'smartphone_feature_columns.joblib')
print("✅ Model saved.")

# ------------------ 5️⃣  Evaluation ------------------
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

print("Test Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=['Healthy','Failure Imminent']))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Healthy','Failure'],
            yticklabels=['Healthy','Failure'])
plt.xlabel("Predicted"); plt.ylabel("Actual"); plt.show()
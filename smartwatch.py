# -*- coding: utf-8 -*-
"""smartwatch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVdcnxaUgUp6QhM8UylqeG4TQkmnl3p4
"""

# ==============================================================================
# Smartwatch Predictive Maintenance â€“ Full Pipeline
# ==============================================================================

import json
import uuid
import random
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from tqdm import tqdm
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# ------------------------------------------------------------------------------
# 1ï¸âƒ£  Simulation Engine â€“ Smartwatch Only
# ------------------------------------------------------------------------------

class DeviceSimulator:
    def __init__(self, device_type, model_name, failure_type):
        self.device_id = f"{device_type.replace('_', '-')}-{uuid.uuid4()}"
        self.device_type, self.model_name, self.failure_type = device_type, model_name, failure_type
        self.current_time = datetime.utcnow() - timedelta(days=random.randint(30, 90))
        self.time_step = timedelta(hours=random.randint(1, 4))
        self.state = self.get_healthy_state()
    def get_healthy_state(self): raise NotImplementedError
    def simulate_failure_step(self): raise NotImplementedError
    def generate_record(self, is_failing=False):
        record = {
            "recordId": str(uuid.uuid4()),
            "deviceId": self.device_id,
            "deviceType": self.device_type,
            "timestamp": self.current_time.isoformat() + "Z",
            "modelName": self.model_name,
            "metrics": self.state.copy(),
            "label": {
                "failure_imminent": is_failing,
                "failure_type": self.failure_type if is_failing else "none"
            }
        }
        self.current_time += self.time_step
        return record
    def run_simulation(self, healthy_records=50, failing_records=10):
        dataset = []
        for _ in range(healthy_records):
            self.state = self.get_healthy_state()
            dataset.append(self.generate_record(is_failing=False))
        for _ in range(failing_records):
            self.simulate_failure_step()
            dataset.append(self.generate_record(is_failing=True))
        return dataset

class SmartwatchSimulator(DeviceSimulator):
    def __init__(self):
        super().__init__("smartwatch", "Samsung Galaxy Watch7", "gps_module_failure")
    def get_healthy_state(self):
        return {
            "positional_accuracy_meters": round(random.uniform(3.0, 5.0), 1),
            "time_to_first_fix_s": random.randint(15, 30),
            "satellite_count": random.randint(10, 15)
        }
    def simulate_failure_step(self):
        self.state["positional_accuracy_meters"] += round(random.uniform(5.0, 15.0), 1)
        self.state["time_to_first_fix_s"] += random.randint(10, 20)
        self.state["satellite_count"] = max(self.state["satellite_count"] - random.randint(1, 2), 0)

print("âœ… Smartwatch simulation engine ready.")

# ------------------------------------------------------------------------------
# 2ï¸âƒ£  Dataset Generation
# ------------------------------------------------------------------------------
NUM_DEVICES = 350  # adjust for more or fewer devices
master_dataset = []

print("ðŸš€ Generating smartwatch dataset...")
for _ in tqdm(range(NUM_DEVICES)):
    sim = SmartwatchSimulator()
    device_records = sim.run_simulation(
        healthy_records=random.randint(30, 50),
        failing_records=random.randint(10, 15)
    )
    master_dataset.extend(device_records)

random.shuffle(master_dataset)
with open('smartwatch_device_narratives.json', 'w') as f:
    json.dump(master_dataset, f)

print(f"âœ… Dataset generated with {len(master_dataset):,} records.")

# ------------------------------------------------------------------------------
# 3ï¸âƒ£  Data Preparation for LSTM
# ------------------------------------------------------------------------------
df = pd.read_json('smartwatch_device_narratives.json')
df_metrics = pd.json_normalize(df['metrics'])
df_labels = pd.json_normalize(df['label'])
df = pd.concat([df.drop(['metrics', 'label', 'recordId', 'modelName'], axis=1),
                df_metrics, df_labels], axis=1)
df.fillna(0, inplace=True)
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.sort_values(by=['deviceId', 'timestamp'], inplace=True)
df['failure_imminent'] = df['failure_imminent'].astype(int)

non_feature_cols = ['deviceId', 'deviceType', 'timestamp', 'failure_type', 'failure_imminent']
feature_columns = df.drop(columns=non_feature_cols).columns.tolist()
print(f"Feature columns: {feature_columns}")

scaler = StandardScaler()
df[feature_columns] = scaler.fit_transform(df[feature_columns])
joblib.dump(scaler, 'smartwatch_lstm_scaler.joblib')

train_ids, test_ids = train_test_split(df['deviceId'].unique(), test_size=0.25, random_state=42)
train_df = df[df['deviceId'].isin(train_ids)]
test_df = df[df['deviceId'].isin(test_ids)]

SEQUENCE_LENGTH = 10

def create_sequences(data_df, features, target_col):
    X, y = [], []
    for _, group in data_df.groupby('deviceId'):
        feat = group[features].values
        label = group[target_col].values
        for i in range(len(group) - SEQUENCE_LENGTH):
            X.append(feat[i:i + SEQUENCE_LENGTH])
            y.append(label[i + SEQUENCE_LENGTH])
    return np.array(X), np.array(y)

print("Creating sequences...")
X_train, y_train = create_sequences(train_df, feature_columns, 'failure_imminent')
X_test, y_test   = create_sequences(test_df, feature_columns, 'failure_imminent')

print("Train shape:", X_train.shape, y_train.shape)
print("Test shape :", X_test.shape,  y_test.shape)

# ------------------------------------------------------------------------------
# 4ï¸âƒ£  LSTM Model
# ------------------------------------------------------------------------------
tf.keras.backend.clear_session()
model = Sequential([
    Input(shape=(SEQUENCE_LENGTH, len(feature_columns))),
    LSTM(64, return_sequences=False),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
print("ðŸ’ª Training model...")
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=64,
    validation_split=0.2,
    callbacks=[early_stopping],
    verbose=1
)
print("âœ… Training complete.")

model.save('smartwatch_lstm_model.keras')
joblib.dump(feature_columns, 'smartwatch_lstm_features.joblib')

# ------------------------------------------------------------------------------
# 5ï¸âƒ£  Evaluation
# ------------------------------------------------------------------------------
print("ðŸ§ª Evaluating on test set...")
y_pred = (model.predict(X_test) > 0.5).astype(int)

acc = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {acc:.4f}")
print("\nClassification Report:\n",
      classification_report(y_test, y_pred, target_names=['Healthy', 'Failure Imminent']))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Healthy', 'Failure'],
            yticklabels=['Healthy', 'Failure'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Smartwatch Failure Prediction")
plt.show()